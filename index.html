<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Enhanced Speech AI Chat</title>
</head>
<body>
    <h1>Enhanced Speech AI Chat</h1>
        <div id="voice-controls">
            <label class="voice-label" for="voice-select">Select Voice:</label>
            <select id="voice-select"></select>
        </div>
        <div id="chat"></div>
        <div id="controls">
            <button id="startBtn">
                <span class="icon">🎤</span>
                Start Recording
            </button>
            <button id="stopBtn" disabled>
                <span class="icon">⏹️</span>
                Stop
            </button>
            <button id="clearBtn">
                <span class="icon">🗑️</span>
                Clear Chat
            </button>
        </div>
        <div id="status"></div>
    </div>
    <script type="module">
            // Check for Speech Synthesis support
    if (!("speechSynthesis" in window && "SpeechSynthesisUtterance" in window)) {
        document.querySelector('.container').insertAdjacentHTML('afterbegin', 
            '<div class="unsupported">Speech Synthesis not supported in this browser</div>'
        );
    }

    // Speech Recognition Setup
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-US';

    // Speech Synthesis Setup
    const synth = window.speechSynthesis;

    // Available voices configuration
    const availableVoices = [
        { name: "Google Deutsch", lang: "de-DE" },
        { name: "Google US English", lang: "en-US" },
        { name: "Google UK English Female", lang: "en-GB" },
        { name: "Google español", lang: "es-ES" },
        { name: "Google français", lang: "fr-FR" },
        { name: "Google 日本語", lang: "ja-JP" }
    ];

    // DOM Elements
    const chatDiv = document.getElementById("chat");
    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const clearBtn = document.getElementById("clearBtn");
    const statusDiv = document.getElementById("status");
    const voiceSelect = document.getElementById("voice-select");

    let isListening = false;
    let transcript = "";
    let isProcessing = false;
    const messages = [];

    // Populate voice selection dropdown
    function populateVoiceList() {
        voiceSelect.innerHTML = ''; // Clear existing options
        availableVoices.forEach((voice, i) => {
            const option = document.createElement("option");
            option.value = i;
            option.textContent = `${voice.name} (${voice.lang})`;
            voiceSelect.appendChild(option);
            
            // Set default to Google UK English Female
            if (voice.lang === "en-GB") {
                voiceSelect.value = i;
            }
        });
    }

    // Initialize voice list when voices are loaded
    synth.onvoiceschanged = populateVoiceList;

    // Initial population in case voices are already loaded
    populateVoiceList();

    // Event Listeners
    startBtn.addEventListener("click", startListening);
    stopBtn.addEventListener("click", stopListening);
    clearBtn.addEventListener("click", clearChat);

    // Start Listening Function
    function startListening() {
        if (!isListening && !isProcessing) {
            try {
                recognition.start();
                isListening = true;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                updateStatus("Listening...", "🎤");
                addMessage("system", "Listening to your voice...");
            } catch (error) {
                handleError("Error starting speech recognition: " + error.message);
            }
        }
    }

    // Stop Listening Function
    function stopListening() {
        if (isListening) {
            recognition.stop();
            isListening = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
            updateStatus("Stopped listening", "⏹️");
            addMessage("system", "Stopped listening.");
        }
    }

    // Clear Chat Function
    function clearChat() {
        if (confirm("Are you sure you want to clear the chat history?")) {
            chatDiv.innerHTML = "";
            messages.length = 0;
            updateStatus("Chat cleared", "🗑️");
        }
    }

    // Update Status Function
    function updateStatus(message, icon = "") {
        statusDiv.textContent = `${icon} ${message}`;
    }

    // Add Message Function
    function addMessage(role, content) {
        const messageDiv = document.createElement("div");
        messageDiv.classList.add("message", role);
        messageDiv.textContent = content;
        chatDiv.appendChild(messageDiv);
        chatDiv.scrollTop = chatDiv.scrollHeight;
    }

    // Handle Error Function
    function handleError(error) {
        console.error(error);
        addMessage("system", `Error: ${error}`);
        updateStatus("Error occurred", "❌");
        stopListening();
    }

    // Speech Recognition Results Handler
    recognition.onresult = (event) => {
        let interimTranscript = "";
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
            const { transcript: segmentTranscript } = event.results[i][0];
            if (event.results[i].isFinal) {
                transcript += segmentTranscript + " ";
                sendMessage(transcript.trim());
                transcript = "";
            } else {
                interimTranscript += segmentTranscript;
            }
        }
        
        updateStatus(interimTranscript ? "Recognizing..." : "Listening...", "🎤");
    };

    // Send Message Function
    async function sendMessage(content) {
        if (!content.trim() || isProcessing) return;
        
        isProcessing = true;
        updateStatus("Processing...", "⚙️");
        
        const newMessage = { role: 'user', content };
        messages.push(newMessage);
        addMessage("user", content);

        try {
            const response = await fetch('http://127.0.0.1:8080/api/chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ messages, role: 'user' }),
            });

            if (!response.ok) {
                throw new Error(`Server responded with status: ${response.status}`);
            }

            const data = await response.json();
            const assistantMessage = { role: 'assistant', content: data.response };
            messages.push(assistantMessage);
            addMessage("assistant", data.response);
            speak(data.response);
            updateStatus("Ready", "✅");
        } catch (error) {
            handleError(`Failed to communicate with the server: ${error.message}`);
        } finally {
            isProcessing = false;
        }
    }

    // Speak Text Function
    function speak(text) {
        if (synth.speaking) {
            synth.cancel();
        }
        
        const utterance = new SpeechSynthesisUtterance(text);
        
        // Set voice properties
        const selectedVoice = availableVoices[voiceSelect.value];
        const systemVoices = synth.getVoices();
        utterance.voice = systemVoices.find(v => v.lang === selectedVoice.lang);
        utterance.lang = selectedVoice.lang;
        utterance.rate = 1;
        utterance.pitch = 1;
        
        // Event handlers
        utterance.onstart = () => updateStatus("Speaking...", "🔊");
        utterance.onend = () => updateStatus("Ready", "✅");
        utterance.onerror = (event) => handleError(`Speech synthesis error: ${event.error}`);
        
        synth.speak(utterance);
    }

    // Error Handlers
    recognition.onerror = (event) => {
        handleError(`Speech recognition error: ${event.error}`);
    };

    recognition.onend = () => {
        if (isListening) {
            try {
                recognition.start();
                updateStatus("Reconnected", "🔄");
            } catch (error) {
                handleError("Failed to restart speech recognition");
            }
        }
    };

    // Initial status
    updateStatus("Ready to start", "✅");
    </script>
</body>
</html>